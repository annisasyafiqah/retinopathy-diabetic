{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'readimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Image\u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mreadimage(\u001b[39m'\u001b[39m\u001b[39mData_Kurangi_Filter\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mTesting\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mdiabetic_images\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDiabetes_1.png\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'readimage'"
     ]
    }
   ],
   "source": [
    "Image= cv2.readimage('Data_Kurangi_Filter\\Testing\\diabetic_images\\Diabetes_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join('Data_Kurangi_Filter/Training')\n",
    "testing_dir = os.path.join('Data_Kurangi_Filter/Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk melakukan augmentasi pada gambar\n",
    "def augment_image(image):\n",
    "    # Flip horizontal\n",
    "    if random.random() < 0.5:\n",
    "        image = np.flip(image, axis=1)\n",
    "\n",
    "    # Flip vertical\n",
    "    if random.random() < 0.5:\n",
    "        image = np.flip(image, axis=0)\n",
    "\n",
    "    # Zoom\n",
    "    zoom_factor = random.uniform(0.7, 1.3)\n",
    "    new_size = (int(image.shape[1] * zoom_factor), int(image.shape[0] * zoom_factor))\n",
    "    image = cv2.resize(image, new_size)\n",
    "\n",
    "    # Shear\n",
    "    shear_factor = random.uniform(-0.2, 0.2)\n",
    "    shear_matrix = np.array([[1, shear_factor, 0], [0, 1, 0]])\n",
    "    image = cv2.warpAffine(image, shear_matrix, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'diabetic_images': 0, 'normal_images': 1}\n"
     ]
    }
   ],
   "source": [
    "# List semua kelas dalam direktori latihan\n",
    "class_list = sorted(os.listdir(train_dir))\n",
    "\n",
    "# Membuat kamus untuk menyimpan indeks kelas\n",
    "class_indices = {class_name: i for i, class_name in enumerate(class_list)}\n",
    "\n",
    "# Contoh penggunaan\n",
    "print(class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (150, 150)\n",
    "batch_size = 2\n",
    "\n",
    "# List semua file gambar dalam direktori latihan\n",
    "file_list = [os.path.join(train_dir, filename) for filename in os.listdir(train_dir)]\n",
    "# Fungsi untuk mengubah dan memuat batch gambar\n",
    "def image_generator(file_list):\n",
    "    while True:\n",
    "        if len(file_list) < batch_size:\n",
    "            raise ValueError(\"Batch size is larger than the number of available images.\")\n",
    "        batch_files = random.sample(file_list, batch_size)\n",
    "        batch_images = []\n",
    "        for file_path in batch_files:\n",
    "            image = read_image(file_path, target_size)\n",
    "            image = augment_image(image)\n",
    "            batch_images.append(image)\n",
    "        yield np.array(batch_images)\n",
    "\n",
    "# Contoh penggunaan generator gambar\n",
    "train_generator = image_generator(file_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split = 0.1  # Persentase data validasi\n",
    "\n",
    "# List semua file gambar dalam direktori latihan\n",
    "file_list = [os.path.join(train_dir, filename) for filename in os.listdir(train_dir)]\n",
    "\n",
    "# Mengacak urutan file gambar\n",
    "random.shuffle(file_list)\n",
    "\n",
    "# Menghitung jumlah data validasi berdasarkan validation_split\n",
    "num_validation_samples = int(validation_split * len(file_list))\n",
    "\n",
    "# Memisahkan data latihan dan validasi\n",
    "train_files = file_list[:-num_validation_samples]\n",
    "validation_files = file_list[-num_validation_samples:]\n",
    "\n",
    "# Membuat instance generator data latihan\n",
    "train_generator = image_generator(train_files)\n",
    "\n",
    "# Membuat instance generator data validasi\n",
    "validation_generator = image_generator(validation_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D:\n",
    "    def __init__(self, num_filters, kernel_size, activation):\n",
    "        self.num_filters = num_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.activation = activation\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        self.weights = np.random.randn(num_filters, kernel_size, kernel_size)\n",
    "        self.biases = np.zeros(num_filters)\n",
    "\n",
    "    def initialize(self, input_shape):\n",
    "        input_channels = input_shape[-1]\n",
    "        kernel_height, kernel_width = self.kernel_size[0], self.kernel_size[1]\n",
    "        self.weights = np.random.randn(kernel_height, kernel_width, input_channels, self.num_filters)\n",
    "        self.bias = np.zeros(self.num_filters)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        input_height, input_width, _ = input_data.shape\n",
    "        kernel_height, kernel_width = self.kernel_size[0], self.kernel_size[1]\n",
    "        output_height = input_height - kernel_height + 1\n",
    "        output_width = input_width - kernel_width + 1\n",
    "        output = np.zeros((input_data.shape[0], output_height, output_width, self.num_filters))\n",
    "\n",
    "        # Convolution operation\n",
    "        for i in range(output_height):\n",
    "            for j in range(output_width):\n",
    "                for k in range(self.num_filters):\n",
    "                    output[:, i, j, k] = np.sum(\n",
    "                        input_data[:, i:i + kernel_height, j:j + kernel_width, :] * self.weights[:, :, :, k],\n",
    "                        axis=(1, 2, 3)\n",
    "                    ) + self.bias[k]\n",
    "\n",
    "        if self.activation == \"relu\":\n",
    "            output = np.maximum(output, 0)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    def __init__(self, pool_size, strides):\n",
    "        self.pool_size = pool_size\n",
    "        self.strides = strides\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        input_height, input_width, num_channels = input_data.shape[1:]\n",
    "        output_height = (input_height - self.pool_size[0]) // self.strides[0] + 1\n",
    "        output_width = (input_width - self.pool_size[1]) // self.strides[1] + 1\n",
    "        output = np.zeros((input_data.shape[0], output_height, output_width, num_channels))\n",
    "\n",
    "        for i in range(output_height):\n",
    "            for j in range(output_width):\n",
    "                receptive_field = input_data[:, i*self.strides[0]:i*self.strides[0]+self.pool_size[0],\n",
    "                                             j*self.strides[1]:j*self.strides[1]+self.pool_size[1], :]\n",
    "                output[:, i, j, :] = np.amax(receptive_field, axis=(1, 2))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    def __init__(self, units, activation=\"relu\"):\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def initialize(self, input_shape):\n",
    "        input_size = np.prod(input_shape)\n",
    "        self.weights = np.random.randn(input_size, self.units) / np.sqrt(input_size)\n",
    "        self.bias = np.zeros(self.units)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        input_flattened = input_data.reshape((input_data.shape[0], -1))\n",
    "        output = np.dot(input_flattened, self.weights) + self.bias\n",
    "\n",
    "        if self.activation == \"relu\":\n",
    "            output = np.maximum(output, 0)\n",
    "        elif self.activation == \"softmax\":\n",
    "            exp_output = np.exp(output)\n",
    "            output = exp_output / np.sum(exp_output, axis=1, keepdims=True)\n",
    "\n",
    "        return output\n",
    "    def get_weights(self):\n",
    "        return self.weights, self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def forward(self, input_data):\n",
    "        return input_data.reshape((input_data.shape[0], -1))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # Avoid numerical instability by subtracting the maximum value\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membangun model\n",
    "model = []\n",
    "model.append(Conv2D(num_filters=32, kernel_size=3, activation=\"relu\"))\n",
    "model.append(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.append(Conv2D(num_filters=64, kernel_size=3, activation=\"relu\"))\n",
    "model.append(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.append(Conv2D(num_filters=128, kernel_size=3, activation=\"relu\"))\n",
    "model.append(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.append(Flatten())\n",
    "model.append(Dense(units=256, activation=\"relu\"))\n",
    "model.append(Dense(units=256, activation=\"relu\"))\n",
    "# model.append(Dense(units=2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1\n",
      "-------------\n",
      "Type: Conv2D\n",
      "Activation: relu\n",
      "Filters: 32\n",
      "Kernel Size: 3\n",
      "\n",
      "Layer 2\n",
      "-------------\n",
      "Type: MaxPool2D\n",
      "\n",
      "Layer 3\n",
      "-------------\n",
      "Type: Conv2D\n",
      "Activation: relu\n",
      "Filters: 64\n",
      "Kernel Size: 3\n",
      "\n",
      "Layer 4\n",
      "-------------\n",
      "Type: MaxPool2D\n",
      "\n",
      "Layer 5\n",
      "-------------\n",
      "Type: Conv2D\n",
      "Activation: relu\n",
      "Filters: 128\n",
      "Kernel Size: 3\n",
      "\n",
      "Layer 6\n",
      "-------------\n",
      "Type: MaxPool2D\n",
      "\n",
      "Layer 7\n",
      "-------------\n",
      "Type: Flatten\n",
      "\n",
      "Layer 8\n",
      "-------------\n",
      "Type: Dense\n",
      "Activation: relu\n",
      "Units: 256\n",
      "\n",
      "Layer 9\n",
      "-------------\n",
      "Type: Dense\n",
      "Activation: relu\n",
      "Units: 256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cetak ringkasan model\n",
    "for i, layer in enumerate(model):\n",
    "    print(f\"Layer {i + 1}\")\n",
    "    print(\"-------------\")\n",
    "    print(f\"Type: {type(layer).__name__}\")\n",
    "    if isinstance(layer, Conv2D):\n",
    "        print(f\"Activation: {layer.activation}\")\n",
    "        print(f\"Filters: {layer.num_filters}\")\n",
    "        print(f\"Kernel Size: {layer.kernel_size}\")\n",
    "    elif isinstance(layer, Dense):\n",
    "        print(f\"Activation: {layer.activation}\")\n",
    "        print(f\"Units: {layer.units}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model optimizer\n",
    "class AdamaxOptimizer:\n",
    "    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        self.t = 0\n",
    "\n",
    "    def initialize(self, parameters):\n",
    "        self.m = [np.zeros_like(param) for param in parameters]\n",
    "        self.v = [np.zeros_like(param) for param in parameters]\n",
    "\n",
    "    def update(self, parameters, gradients):\n",
    "        self.t += 1\n",
    "\n",
    "        for i in range(len(parameters)):\n",
    "            self.m[i] = self.beta1 * self.m[i] + (1 - self.beta1) * gradients[i]\n",
    "            self.v[i] = np.maximum(self.beta2 * self.v[i], np.abs(gradients[i]))\n",
    "            lr_t = self.learning_rate / (1 - self.beta1 ** self.t)\n",
    "\n",
    "            # Update weights\n",
    "            parameters[i].weights -= lr_t * self.m[i] / (self.v[i] + 1e-8)\n",
    "\n",
    "            # Update biases\n",
    "            parameters[i].bias -= lr_t * np.mean(self.m[i]) / (np.mean(self.v[i]) + 1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Membangun model optimizer\n",
    "optimizer = AdamaxOptimizer(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi bobot dan bias model\n",
    "parameters = []\n",
    "for layer in model:\n",
    "    if isinstance(layer, Conv2D) or isinstance(layer, Dense):\n",
    "        parameters.append(layer.weights)\n",
    "        parameters.append(layer.bias)\n",
    "\n",
    "optimizer.initialize(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisikan loss function dan metrics\n",
    "def categorical_crossentropy(y_true, y_pred):\n",
    "    y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)  # Avoid numerical instability when taking the logarithm\n",
    "    return -np.mean(y_true * np.log(y_pred))\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "    return np.mean(y_true == y_pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menghitung loss antara output model dan label batch\n",
    "def calculate_loss(output, batch_y):\n",
    "    # Konversi label batch menjadi array numpy\n",
    "    batch_y = np.array(batch_y)\n",
    "\n",
    "    # Hitung loss antara output dan label menggunakan metode yang sesuai\n",
    "    loss = np.mean((output - batch_y)**2)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradients(loss, weights, biases, train_data_flat, train_labels_binary):\n",
    "    num_samples = train_data_flat.shape[0]\n",
    "    \n",
    "    # Compute y_pred\n",
    "    logits = np.dot(train_data_flat, weights) + biases\n",
    "    probabilities = softmax(logits)\n",
    "    y_pred = np.argmax(probabilities, axis=1)\n",
    "    \n",
    "    # Compute gradient of loss with respect to logits\n",
    "    gradient_logits = probabilities.copy()\n",
    "    \n",
    "    # Backpropagation\n",
    "    gradient_logits[range(num_samples), train_labels_binary.flatten()] -= 1\n",
    "    gradient_logits /= num_samples\n",
    "    \n",
    "    # Compute gradients of loss with respect to weights and biases\n",
    "    d_weights = np.dot(train_data_flat.T, gradient_logits)\n",
    "    d_biases = np.sum(gradient_logits, axis=0)\n",
    "    \n",
    "    gradients = {'weights': d_weights, 'biases': d_biases}\n",
    "    \n",
    "    return gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk memperbarui parameter model menggunakan gradien\n",
    "def update_parameters(parameters, gradients, learning_rate):\n",
    "    updated_parameters = {}\n",
    "\n",
    "    for param_name, gradient in gradients.items():\n",
    "        updated_parameters[param_name] = parameters[param_name] - learning_rate * gradient\n",
    "\n",
    "    return updated_parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, train_labels, epochs, learning_rate):\n",
    "    num_samples = train_data.shape[0]\n",
    "    input_dim = train_data.shape[1:]\n",
    "    num_classes = len(np.unique(train_labels))\n",
    "\n",
    "    # Initialize weights and biases\n",
    "    weights = np.random.randn(np.prod(input_dim), num_classes)\n",
    "    biases = np.zeros(num_classes)\n",
    "\n",
    "    # Flatten the input data\n",
    "    train_data_flat = train_data.reshape(num_samples, -1)\n",
    "\n",
    "    # Convert labels to binary format\n",
    "    train_labels_binary = np.expand_dims(train_labels, axis=1)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        # Forward propagation\n",
    "        logits = np.dot(train_data_flat, weights) + biases\n",
    "        probabilities = softmax(logits)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = categorical_crossentropy(train_labels_binary, probabilities)\n",
    "        average_loss = np.mean(loss)\n",
    "        \n",
    "        # Backpropagation\n",
    "        gradient = probabilities\n",
    "        gradient[range(num_samples), train_labels] -= 1\n",
    "        gradient /= num_samples\n",
    "\n",
    "        d_weights = np.dot(train_data_flat.T, gradient)\n",
    "        d_biases = np.sum(gradient, axis=0)\n",
    "\n",
    "        # Update weights and biases\n",
    "        weights -= learning_rate * d_weights\n",
    "        biases -= learning_rate * d_biases\n",
    "        # Print epoch information\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - Loss: {average_loss}\")\n",
    "\n",
    "\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 - Loss: 4.020898737730378\n",
      "Epoch 2/150 - Loss: 3.854163526985601\n",
      "Epoch 3/150 - Loss: 3.9839916201943115\n",
      "Epoch 4/150 - Loss: 3.9442058143423555\n",
      "Epoch 5/150 - Loss: 3.896378118485869\n",
      "Epoch 6/150 - Loss: 3.8572704167122644\n",
      "Epoch 7/150 - Loss: 3.7619048910782267\n",
      "Epoch 8/150 - Loss: 3.7493612610128806\n",
      "Epoch 9/150 - Loss: 3.7014774973378373\n",
      "Epoch 10/150 - Loss: 3.7766137370484376\n",
      "Epoch 11/150 - Loss: 3.9376762573726514\n",
      "Epoch 12/150 - Loss: 3.9967137584596726\n",
      "Epoch 13/150 - Loss: 3.9995370600724196\n",
      "Epoch 14/150 - Loss: 3.9972628313128804\n",
      "Epoch 15/150 - Loss: 3.9989802643887957\n",
      "Epoch 16/150 - Loss: 3.996625761098409\n",
      "Epoch 17/150 - Loss: 3.9888470028396386\n",
      "Epoch 18/150 - Loss: 3.9845168662843777\n",
      "Epoch 19/150 - Loss: 3.9811320559607144\n",
      "Epoch 20/150 - Loss: 3.9420699955913303\n",
      "Epoch 21/150 - Loss: 3.9805281807474744\n",
      "Epoch 22/150 - Loss: 3.905214080291628\n",
      "Epoch 23/150 - Loss: 3.9879667322668184\n",
      "Epoch 24/150 - Loss: 3.897695517652053\n",
      "Epoch 25/150 - Loss: 4.0014014232451425\n",
      "Epoch 26/150 - Loss: 3.9058333401140533\n",
      "Epoch 27/150 - Loss: 4.0022663127411615\n",
      "Epoch 28/150 - Loss: 3.9084380932641625\n",
      "Epoch 29/150 - Loss: 3.9980027347334954\n",
      "Epoch 30/150 - Loss: 3.924465904440777\n",
      "Epoch 31/150 - Loss: 3.994732203359589\n",
      "Epoch 32/150 - Loss: 3.9527091038886706\n",
      "Epoch 33/150 - Loss: 3.9938964139453255\n",
      "Epoch 34/150 - Loss: 3.9701936364217456\n",
      "Epoch 35/150 - Loss: 3.9932412804206847\n",
      "Epoch 36/150 - Loss: 3.980569696253566\n",
      "Epoch 37/150 - Loss: 3.992677508072769\n",
      "Epoch 38/150 - Loss: 3.9883041604248\n",
      "Epoch 39/150 - Loss: 3.992279006850755\n",
      "Epoch 40/150 - Loss: 3.993476844629514\n",
      "Epoch 41/150 - Loss: 3.9919558815408167\n",
      "Epoch 42/150 - Loss: 3.9977328022909155\n",
      "Epoch 43/150 - Loss: 3.9916519008302185\n",
      "Epoch 44/150 - Loss: 4.000428211236391\n",
      "Epoch 45/150 - Loss: 3.991360928385138\n",
      "Epoch 46/150 - Loss: 4.00245605442867\n",
      "Epoch 47/150 - Loss: 3.991076724855194\n",
      "Epoch 48/150 - Loss: 4.003971643382986\n",
      "Epoch 49/150 - Loss: 3.9907897194511186\n",
      "Epoch 50/150 - Loss: 4.004635998526096\n",
      "Epoch 51/150 - Loss: 3.9904783952830085\n",
      "Epoch 52/150 - Loss: 4.005210383299417\n",
      "Epoch 53/150 - Loss: 3.990112256720212\n",
      "Epoch 54/150 - Loss: 4.0055248232441185\n",
      "Epoch 55/150 - Loss: 3.989692285778141\n",
      "Epoch 56/150 - Loss: 4.00542083551848\n",
      "Epoch 57/150 - Loss: 3.989255136856293\n",
      "Epoch 58/150 - Loss: 4.003480674149813\n",
      "Epoch 59/150 - Loss: 3.988862744311474\n",
      "Epoch 60/150 - Loss: 3.9981016806714083\n",
      "Epoch 61/150 - Loss: 3.9882581909252166\n",
      "Epoch 62/150 - Loss: 3.9937325150914607\n",
      "Epoch 63/150 - Loss: 3.9872617697685997\n",
      "Epoch 64/150 - Loss: 3.988930002308647\n",
      "Epoch 65/150 - Loss: 3.9861433504818815\n",
      "Epoch 66/150 - Loss: 3.9827361712150173\n",
      "Epoch 67/150 - Loss: 3.9848658927517473\n",
      "Epoch 68/150 - Loss: 3.9771312269704846\n",
      "Epoch 69/150 - Loss: 3.984884133926648\n",
      "Epoch 70/150 - Loss: 3.975533065707522\n",
      "Epoch 71/150 - Loss: 3.984672314556558\n",
      "Epoch 72/150 - Loss: 3.976154164069235\n",
      "Epoch 73/150 - Loss: 3.98428921668611\n",
      "Epoch 74/150 - Loss: 3.978315486378449\n",
      "Epoch 75/150 - Loss: 3.984212517787571\n",
      "Epoch 76/150 - Loss: 3.981035728228824\n",
      "Epoch 77/150 - Loss: 3.9843620113401697\n",
      "Epoch 78/150 - Loss: 3.983151867149728\n",
      "Epoch 79/150 - Loss: 3.984543858687\n",
      "Epoch 80/150 - Loss: 3.982715968834464\n",
      "Epoch 81/150 - Loss: 3.9851983358746894\n",
      "Epoch 82/150 - Loss: 3.984193094613048\n",
      "Epoch 83/150 - Loss: 3.98532781825921\n",
      "Epoch 84/150 - Loss: 3.984335054857392\n",
      "Epoch 85/150 - Loss: 3.985899830623459\n",
      "Epoch 86/150 - Loss: 3.9860968107158037\n",
      "Epoch 87/150 - Loss: 3.985646552961816\n",
      "Epoch 88/150 - Loss: 3.985987992202794\n",
      "Epoch 89/150 - Loss: 3.9861938164111708\n",
      "Epoch 90/150 - Loss: 3.986706659260367\n",
      "Epoch 91/150 - Loss: 3.986057038186447\n",
      "Epoch 92/150 - Loss: 3.9866669279569096\n",
      "Epoch 93/150 - Loss: 3.98652191956961\n",
      "Epoch 94/150 - Loss: 3.9858385260596707\n",
      "Epoch 95/150 - Loss: 3.9866276976152584\n",
      "Epoch 96/150 - Loss: 3.9821705261088822\n",
      "Epoch 97/150 - Loss: 3.987014905276601\n",
      "Epoch 98/150 - Loss: 3.97901668042296\n",
      "Epoch 99/150 - Loss: 3.987269243596562\n",
      "Epoch 100/150 - Loss: 3.975491465227985\n",
      "Epoch 101/150 - Loss: 3.987621209989202\n",
      "Epoch 102/150 - Loss: 3.9721465715289774\n",
      "Epoch 103/150 - Loss: 3.9879477562725483\n",
      "Epoch 104/150 - Loss: 3.968712002295151\n",
      "Epoch 105/150 - Loss: 3.988375866279697\n",
      "Epoch 106/150 - Loss: 3.9652714173333674\n",
      "Epoch 107/150 - Loss: 3.989006810844732\n",
      "Epoch 108/150 - Loss: 3.9616899808555166\n",
      "Epoch 109/150 - Loss: 3.989611472416897\n",
      "Epoch 110/150 - Loss: 3.9578355986636846\n",
      "Epoch 111/150 - Loss: 3.989684643622411\n",
      "Epoch 112/150 - Loss: 3.9545678587938404\n",
      "Epoch 113/150 - Loss: 3.9882078639683884\n",
      "Epoch 114/150 - Loss: 3.9536616416439183\n",
      "Epoch 115/150 - Loss: 3.9854544760849455\n",
      "Epoch 116/150 - Loss: 3.9525654519806737\n",
      "Epoch 117/150 - Loss: 3.9840812362571567\n",
      "Epoch 118/150 - Loss: 3.95093334761731\n",
      "Epoch 119/150 - Loss: 3.984507112781937\n",
      "Epoch 120/150 - Loss: 3.950323695235198\n",
      "Epoch 121/150 - Loss: 3.9850392602030467\n",
      "Epoch 122/150 - Loss: 3.950314771418448\n",
      "Epoch 123/150 - Loss: 3.984668883549525\n",
      "Epoch 124/150 - Loss: 3.950667550261287\n",
      "Epoch 125/150 - Loss: 3.9835085402878634\n",
      "Epoch 126/150 - Loss: 3.951125961213771\n",
      "Epoch 127/150 - Loss: 3.982519291799865\n",
      "Epoch 128/150 - Loss: 3.9515540420704416\n",
      "Epoch 129/150 - Loss: 3.9816745755102865\n",
      "Epoch 130/150 - Loss: 3.9520071488443818\n",
      "Epoch 131/150 - Loss: 3.9808090574181474\n",
      "Epoch 132/150 - Loss: 3.952503928702605\n",
      "Epoch 133/150 - Loss: 3.979948617975261\n",
      "Epoch 134/150 - Loss: 3.9523298560141416\n",
      "Epoch 135/150 - Loss: 3.9791422346681067\n",
      "Epoch 136/150 - Loss: 3.95202731859035\n",
      "Epoch 137/150 - Loss: 3.9784666973333667\n",
      "Epoch 138/150 - Loss: 3.952026399683025\n",
      "Epoch 139/150 - Loss: 3.9775973326621408\n",
      "Epoch 140/150 - Loss: 3.952426645948591\n",
      "Epoch 141/150 - Loss: 3.976118355222112\n",
      "Epoch 142/150 - Loss: 3.9531757403703005\n",
      "Epoch 143/150 - Loss: 3.974984868078002\n",
      "Epoch 144/150 - Loss: 3.9541450800207683\n",
      "Epoch 145/150 - Loss: 3.9740862631758502\n",
      "Epoch 146/150 - Loss: 3.955255726052309\n",
      "Epoch 147/150 - Loss: 3.973328373133677\n",
      "Epoch 148/150 - Loss: 3.955933474172481\n",
      "Epoch 149/150 - Loss: 3.9726462800309172\n",
      "Epoch 150/150 - Loss: 3.955653673796567\n"
     ]
    }
   ],
   "source": [
    "# Mendefinisikan folder yang berisi data latihan\n",
    "train_folder = 'Data_Kurangi_Filter/Training/'\n",
    "\n",
    "# Mendefinisikan kelas atau label yang sesuai dengan nama folder\n",
    "labels = ['normal_images', 'diabetic_images']\n",
    "\n",
    "# Menginisialisasi list untuk menyimpan data latihan dan label\n",
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "# Melakukan iterasi pada setiap folder kelas\n",
    "for label_index, label in enumerate(labels):\n",
    "    folder_path = os.path.join(train_folder, label)\n",
    "    \n",
    "    # Melakukan iterasi pada setiap file dalam folder kelas\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Membaca dan memproses gambar\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Ubah ke format warna RGB jika perlu\n",
    "        image = cv2.resize(image, (224, 224))  # Ubah ukuran gambar jika perlu\n",
    "        image = image / 255.0  # Normalisasi pixel\n",
    "        image\n",
    "        # Menyimpan data latihan dan label ke dalam list\n",
    "        train_data.append(image)\n",
    "        train_labels.append(label_index)\n",
    "\n",
    "# Mengubah list menjadi array numpy\n",
    "train_data = np.array(train_data)\n",
    "train_labels = np.array(train_labels)\n",
    "train_data = np.expand_dims(train_data, axis=-1)\n",
    "\n",
    "learning_rate = 0.01\n",
    "epochs = 150\n",
    "\n",
    "weights = train_model(train_data, train_labels, epochs, learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten hasil segmentasi menjadi vektor input\n",
    "input_nn = train_data[1].flatten()\n",
    "# Normalisasi input menjadi nilai antara 0 dan 1\n",
    "input_nn = input_nn / np.max(input_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi aktivasi sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Fungsi aktivasi turunan sigmoid\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Kelas NeuralNetwork\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Inisialisasi bobot dengan nilai acak\n",
    "        self.weights1 = np.random.randn(input_size, hidden_size)\n",
    "        self.weights2 = np.random.randn(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Perhitungan output dari input melalui hidden layer\n",
    "        self.hidden_output = sigmoid(np.dot(X, self.weights1))\n",
    "\n",
    "        # Perhitungan output akhir dari hidden layer melalui output layer\n",
    "        self.output = sigmoid(np.dot(self.hidden_output, self.weights2))\n",
    "\n",
    "    def train(self, X, y, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            # Feedforward\n",
    "            self.forward(X)\n",
    "\n",
    "            # Perhitungan error\n",
    "            error = y - self.output\n",
    "\n",
    "            # Perhitungan gradien dan penyesuaian bobot\n",
    "            delta_output = error * sigmoid_derivative(self.output)\n",
    "            delta_hidden = np.dot(delta_output, self.weights2.T) * sigmoid_derivative(self.hidden_output)\n",
    "\n",
    "            self.weights2 += np.dot(self.hidden_output.T, delta_output)\n",
    "            self.weights1 += np.dot(X.T, delta_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi dan melatih neural network\n",
    "nn = NeuralNetwork(input_size=input_nn.shape[0], hidden_size=4, output_size=1)\n",
    "nn.train(np.expand_dims(input_nn, axis=0), np.array([[1]]), epochs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99588483]]\n"
     ]
    }
   ],
   "source": [
    "prediksi = nn.output\n",
    "print(prediksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Layer:      [Input Shape]\n",
      "-------------------------------\n",
      "Hidden Layer: [Hidden Shape]\n",
      "-------------------------------\n",
      "Output Layer:   [Output Shape]\n"
     ]
    }
   ],
   "source": [
    "def plot_model():\n",
    "    input_layer = 'Input Layer:      [Input Shape]'\n",
    "    hidden_layer = 'Hidden Layer: [Hidden Shape]'\n",
    "    output_layer = 'Output Layer:   [Output Shape]'\n",
    "\n",
    "    # Menentukan panjang garis horizontal sesuai dengan panjang layer terpanjang\n",
    "    max_length = max(len(input_layer), len(hidden_layer), len(output_layer))\n",
    "    horizontal_line = '-' * max_length\n",
    "\n",
    "    # Menampilkan plot model\n",
    "    print(input_layer)\n",
    "    print(horizontal_line)\n",
    "    print(hidden_layer)\n",
    "    print(horizontal_line)\n",
    "    print(output_layer)\n",
    "\n",
    "# Memanggil fungsi plot_model untuk membuat plot model\n",
    "plot_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[643], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m preprocessed_image \u001b[39m=\u001b[39m preprocess_image(pred_path, target_size)\n\u001b[0;32m     26\u001b[0m \u001b[39m# Make the prediction using your custom model\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m predicted_class, confidence \u001b[39m=\u001b[39m predict(preprocessed_image, model)\n\u001b[0;32m     29\u001b[0m \u001b[39m# Process and display the prediction results\u001b[39;00m\n\u001b[0;32m     30\u001b[0m class_names \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mnormal_images\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdiabetic_images\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# Define the list of class names\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[643], line 14\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(image_array, model)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(image_array, model):\n\u001b[1;32m---> 14\u001b[0m     prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(image_array)\n\u001b[0;32m     15\u001b[0m     predicted_class \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(prediction)  \u001b[39m# Retrieve the predicted class index\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     confidence \u001b[39m=\u001b[39m prediction[\u001b[39m0\u001b[39m, predicted_class]  \u001b[39m# Retrieve the confidence score of the predicted class\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the necessary functions for preprocessing and prediction\n",
    "def preprocess_image(image_path, target_size):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read the image in grayscale\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = cv2.addWeighted(img, 4, cv2.GaussianBlur(img, (0, 0), 40), -4, 128)\n",
    "    img = img.astype('float32') / 255.0  # Normalize the image\n",
    "    img = np.expand_dims(img, axis=0)  # Add an extra dimension\n",
    "    return img\n",
    "\n",
    "def predict(image_array, model):\n",
    "    prediction = model.predict(image_array)\n",
    "    predicted_class = np.argmax(prediction)  # Retrieve the predicted class index\n",
    "    confidence = prediction[0, predicted_class]  # Retrieve the confidence score of the predicted class\n",
    "    return predicted_class, confidence\n",
    "\n",
    "# Set the path to the input image\n",
    "pred_path = \"normal_images/10_left.jpeg\"\n",
    "target_size = (150, 150)\n",
    "\n",
    "# Preprocess the image\n",
    "preprocessed_image = preprocess_image(pred_path, target_size)\n",
    "\n",
    "# Make the prediction using your custom model\n",
    "predicted_class, confidence = predict(preprocessed_image, model)\n",
    "\n",
    "# Process and display the prediction results\n",
    "class_names = ['normal_images', 'diabetic_images']  # Define the list of class names\n",
    "predicted_class_name = class_names[predicted_class]\n",
    "print(\"The image is predicted to belong to the category {} with {:.2f}% confidence.\"\n",
    "      .format(predicted_class_name, confidence * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_operation(image_array, num_filters, kernel_size, activation):\n",
    "    # Get the dimensions of the image\n",
    "    image_height, image_width, _ = image_array.shape\n",
    "\n",
    "    # Extract the height and width values from the kernel_size tuple\n",
    "    kernel_height, kernel_width = kernel_size\n",
    "\n",
    "    # Calculate the padding size based on the kernel size\n",
    "    padding_height = kernel_height // 2\n",
    "    padding_width = kernel_width // 2\n",
    "\n",
    "    # Add padding to the image\n",
    "    padded_image = np.pad(image_array, ((padding_height, padding_height), (padding_width, padding_width), (0, 0)), mode='constant')\n",
    "\n",
    "    # Initialize the output result\n",
    "    output_height = image_height\n",
    "    output_width = image_width\n",
    "    output = np.zeros((output_height, output_width, num_filters))\n",
    "\n",
    "    # Apply convolution operation\n",
    "    for i in range(output_height):\n",
    "        for j in range(output_width):\n",
    "            for k in range(num_filters):\n",
    "                receptive_field = padded_image[i:i + kernel_height, j:j + kernel_width, :]\n",
    "                num_channels = receptive_field.shape[-1]\n",
    "                filter_weights = np.random.randn(kernel_height, kernel_width, num_channels)\n",
    "                output[i, j, k] = np.sum(receptive_field * filter_weights)\n",
    "\n",
    "    # Apply activation function\n",
    "    if activation == \"relu\":\n",
    "        output = np.maximum(output, 0)\n",
    "    elif activation == \"sigmoid\":\n",
    "        output = 1 / (1 + np.exp(-output))\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_operation(image_array):\n",
    "    # Flatten the image array into a 1D array\n",
    "    flattened_array = image_array.flatten()\n",
    "\n",
    "    return flattened_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dense_layer(input_data, weights, activation):\n",
    "    # Perform matrix multiplication between input_data and weights\n",
    "    output = np.dot(input_data, weights)\n",
    "    \n",
    "    if activation == 'relu':\n",
    "        output = relu(output)\n",
    "    elif activation == 'sigmoid':\n",
    "        output = sigmoid(output)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_array, model):\n",
    "    result = image_array.copy()\n",
    "    for layer in model:\n",
    "        if isinstance(layer, Conv2D):\n",
    "            num_filters = layer.num_filters\n",
    "            kernel_size = layer.kernel_size\n",
    "            activation = layer.activation\n",
    "\n",
    "            # Perform convolution operation manually\n",
    "            result = convolution_operation(result, num_filters, kernel_size, activation)\n",
    "        elif isinstance(layer, Flatten):\n",
    "            # Perform flattening operation\n",
    "            result = flatten_operation(result)\n",
    "        elif isinstance(layer, Dense):\n",
    "            weights = layer.weights\n",
    "            activation = layer.activation\n",
    "\n",
    "            # Perform dense operation manually\n",
    "            result = dense_layer(result, weights, activation)\n",
    "\n",
    "    predicted_class = np.argmax(result)  # Retrieve the predicted class index\n",
    "    return predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
